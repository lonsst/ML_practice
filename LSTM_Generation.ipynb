{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lonsst/ML_practice/blob/main/LSTM_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJzHKITyIDRB",
        "outputId": "93fc733d-e630-445b-d75e-8d5afa8660a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00WqJSk-INdl",
        "outputId": "9fbfd887-3bc7-4d52-f36b-9e01c9624c07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание 1.\n",
        "\n",
        "Загрузите текст из произведений Ницше ('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt').\n",
        "Выведете следующее:\n",
        "А) длину всего корпуса;\n",
        "Б) количество предложений;\n",
        "В) сколько всего символов используется?"
      ],
      "metadata": {
        "id": "oDa8To9FIU5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "metadata": {
        "id": "_byP-_sSIQWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import RMSprop\n",
        "#from keras.utils.data_utils import get_file\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io"
      ],
      "metadata": {
        "id": "AAsqisChGhcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kw_E7I-sIv2T",
        "outputId": "3bf349ad-13cf-461e-e55d-ba5f0afa614a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = './nietzsche.txt'\n",
        "nietzsche_text = open(path).read().lower()"
      ],
      "metadata": {
        "id": "KnP2mQxqIYyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Длина корпуса"
      ],
      "metadata": {
        "id": "EMyT0t1YIed4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_length = len(nietzsche_text)\n",
        "print(f'Длина корпуса: {corpus_length} символов')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59g7DMiLIgAd",
        "outputId": "c6b07739-d272-43b8-fabd-4715e1970b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Длина корпуса: 600893 символов\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Количество предложений"
      ],
      "metadata": {
        "id": "a7Gv3gyLIkLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = sent_tokenize(nietzsche_text)\n",
        "num_sentences = len(sentences)\n",
        "print(f'Количество предложений: {num_sentences}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuQLhkO7InnB",
        "outputId": "d3816a09-3bdf-45b1-db7d-a69e851446aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество предложений: 2864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сколько символов используется"
      ],
      "metadata": {
        "id": "yyZ7gY9RI8ld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_characters = sorted(list(set(nietzsche_text)))\n",
        "num_unique_characters = len(unique_characters)\n",
        "print(f'Количество уникальных символов: {num_unique_characters}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYjyVR3RJBHm",
        "outputId": "c87f5e2a-9e87-4b71-a60f-d8b498e9e8cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество уникальных символов: 57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_indices = dict((c, i) for i, c in enumerate(unique_characters))\n",
        "indices_char = dict((i, c) for i, c in enumerate(unique_characters))"
      ],
      "metadata": {
        "id": "tZ6VxhR0K7ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание 2.\n",
        "\n",
        "Сократите текст наполовину избыточными последовательностями символов maxlen"
      ],
      "metadata": {
        "id": "YJHD1g3yJJZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "J8ltU9vyJOH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(nietzsche_text) - maxlen, step):\n",
        "    sentences.append(nietzsche_text[i: i + maxlen])\n",
        "    next_chars.append(nietzsche_text[i + maxlen])\n",
        "print('nb sequences:', len(sentences))\n",
        "\n",
        "print('Vectorization...')\n",
        "x = np.zeros((len(sentences), maxlen, len(unique_characters)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(unique_characters)), dtype=np.bool)\n",
        "for i, (sentence, next_char) in enumerate(zip(sentences, next_chars)):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_char]] = 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAXNWKuaLKd3",
        "outputId": "0c2c8f4c-56ff-45d9-c224-891824a69982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nb sequences: 200285\n",
            "Vectorization...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-05b7409846d0>:12: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  x = np.zeros((len(sentences), maxlen, len(unique_characters)), dtype=np.bool)\n",
            "<ipython-input-11-05b7409846d0>:13: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y = np.zeros((len(sentences), len(unique_characters)), dtype=np.bool)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание 3.\n",
        "\n",
        "Создайте модель LSTM для генерации текста\n",
        "\n",
        "А) Напишите вспомогательную функцию для выборки индекса из массива вероятностей\n",
        "\n",
        "Б) Напишите функцию, которая будет вызываться в конце каждой эпохи и печатать сгенерированный текст\n",
        "\n",
        "В) Запустите модель на обучение\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_gd0-ecbLveK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "metadata": {
        "id": "2eMWqNFrL4Lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, seed_text, length, temperature):\n",
        "    generated_text = seed_text\n",
        "    for _ in range(length):\n",
        "        x_pred = np.zeros((1, maxlen, len(unique_characters)))\n",
        "        for t, char in enumerate(seed_text):\n",
        "            x_pred[0, t, char_indices[char]] = 1.0\n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds, temperature)\n",
        "        next_char = indices_char[next_index]\n",
        "        generated_text += next_char\n",
        "        seed_text = seed_text[1:] + next_char\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "0rT3_nzQMzsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "    print()\n",
        "    print(f'\\n----- Эпоха {epoch + 1} завершена. Генерируем текст:')\n",
        "\n",
        "    start_index = random.randint(0, len(nietzsche_text) - maxlen - 1)\n",
        "    seed_text = nietzsche_text[start_index: start_index + maxlen]\n",
        "\n",
        "    for temperature in [0.2, 0.5, 1.0]:\n",
        "        print('----- Temperature:', temperature)\n",
        "        generated_text = generate_text(model, seed_text, 400, temperature)\n",
        "        print(generated_text)"
      ],
      "metadata": {
        "id": "IEvb-AoIM_ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(unique_characters))))\n",
        "model.add(Dense(len(unique_characters), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "AFHEUsTpNWs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x, y, batch_size=128, epochs=10, callbacks=[LambdaCallback(on_epoch_end=on_epoch_end)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5j4pKOdN6Mh",
        "outputId": "a7a0f992-49f7-4383-a592-9a22a4aca0f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1564/1565 [============================>.] - ETA: 0s - loss: 2.5529\n",
            "\n",
            "----- Эпоха 1 завершена. Генерируем текст:\n",
            "----- Temperature: 0.2\n",
            "a man could bear and take upon himself, the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the hererest of alle the the the the the the the the the mat of moment of the the the the the the the the the the the the the the the the the the the the the the the the the the the the besting of the sereste the the the the mand the the the the the the the sore the the the the p\n",
            "----- Temperature: 0.5\n",
            "a man could bear and take upon himself, the int and and raperente the the the and mate in them an amene wore fo ang of the the that the thes of whe pmat not at of and tor the mad the he the the cion of and as the of the in the cortist and mores and and in the core ous of in the phithian al the tho lara and ind the hall and is in the tore and af be the prof and of memese of the corlonath the the cereat in antels ant sod and at the fore\n",
            "s\n",
            "----- Temperature: 1.0\n",
            "a man could bear and take upon himself, the il whay sinver the meprase nobly berthon enmat\n",
            "enca thotor thet il dinhanve boit badsancedsiwby-enthacd\n",
            "\"rath a. ph'ongoed, ant he whexrelit\n",
            "pitele kof pr.senectpint eninent wfid ssest af beate inm. an inasom frowharmir\n",
            "hancre thithero thas cwiof a mio pithecsus swals the tra vecerjmunastocnendd tha practer-atigizgetsor and mucisusty mom me\"bltistofhe , breenmcancar beltour hhiins\n",
            "wangrorow su\n",
            "1565/1565 [==============================] - 165s 104ms/step - loss: 2.5528\n",
            "Epoch 2/10\n",
            "1564/1565 [============================>.] - ETA: 0s - loss: 2.1914\n",
            "\n",
            "----- Эпоха 2 завершена. Генерируем текст:\n",
            "----- Temperature: 0.2\n",
            "p till then had not only to be honoured the more the the the sentert and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and the preance and and inderente the and and and and and and the concestion and and and and and and and and and and and and and and in the consenting the preating the preand the consenting and in the concenting of the \n",
            "----- Temperature: 0.5\n",
            "p till then had not only to be honoured and as pricaine to the insting the and inderane ind in the and and with ald and which the ispanon porsert of and cand and in the art aster and rangely somelititation as and and and cans deiventing and andict of and in the dengease the corsint and the mars the cont of a buden it so the procelf and is songes of the conce for he chand tore conterpain the and this in the porsond and and of the exprima\n",
            "----- Temperature: 1.0\n",
            "p till then had not only to be honoured erpirigas to lataintountant prtycond, notadd, to nte fretods. dres, ber wive rould bowasce a\n",
            "for muncilf homor mhanslaes encin of buctlint, is wist:st lamedisest\" lesonqoriantifule.-erilt, og sideating alland, in goxticint. have hmon-wimpant conming ap acernce ifde diodisudith on jichary whisn erterrle sreegr\n",
            "more\n",
            "feriringt of is\n",
            "wints acans of\n",
            "simash muthest anis\n",
            "asilencaly t atison as ofwerte on\n",
            "1565/1565 [==============================] - 163s 104ms/step - loss: 2.1914\n",
            "Epoch 3/10\n",
            "1564/1565 [============================>.] - ETA: 0s - loss: 2.0587\n",
            "\n",
            "----- Эпоха 3 завершена. Генерируем текст:\n",
            "----- Temperature: 0.2\n",
            "reflection of outside forms\n",
            "and events has and at and and and and and and and and and and the preaster and and as a mand to the preastion and and and and as a with the promation of the preastion of the somention and of the stand the conterest of the mand and the proustion and and and as and the preastion of the preation of the as and and and are the pralition of the serfertion and and the sonting and a sour the as and and and as as as a\n",
            "----- Temperature: 0.5\n",
            "reflection of outside forms\n",
            "and events hat in the deristed to the preates a sostict of the for it the paros and to the primation, are the candion as the ghally sughated, in the reake of the sensarate the beting thes indertation ans is blever and rathing what compeation as is morable surdation and deave moraneste sact be which of and to the is condicily that gatily hat the melfers wat in which contersed and a stirition of who as as the w\n",
            "----- Temperature: 1.0\n",
            "reflection of outside forms\n",
            "and events hable dastions, in istitting\n",
            "the dasto-son to ore\n",
            "inmaiven sem phestous thescasidet), \" hom to suncy was in neace a vove!. the filumes batdired an\n",
            "i\n",
            "spacciod, is to thithem man in whythe, the\n",
            "grations to thingsend of hoved modky to is waokt mey do kmalitaly melasciog monts?--the copredian ufsalt nat escictids fit?-the maition gowantien lid thenes a as as crowearisclyse onccorcuanfus phapoing\n",
            "to liv\n",
            "1565/1565 [==============================] - 163s 104ms/step - loss: 2.0587\n",
            "Epoch 4/10\n",
            "1565/1565 [==============================] - ETA: 0s - loss: 1.9681\n",
            "\n",
            "----- Эпоха 4 завершена. Генерируем текст:\n",
            "----- Temperature: 0.2\n",
            "almost feminine incapacity for witnessing and and and the sore the strente and and and the has and the sore and and and and and the sould and the songer and the soul the sore the soll the self and the sull has and the sould and the sore and the sond the self and and and and the reast and and the sone the sore and and the sore and and the sore of the sore the has and and and and the sore the manter and and and and and and the stand and t\n",
            "----- Temperature: 0.5\n",
            "almost feminine incapacity for witnessing the soully the most for the condertion is at the sanged the scertian, thes of the sore the courst\n",
            "been the pharoneds hat the sored to the simelitions and whe has somally the reored all of the promon one in this and of the lost for the stromong ham the minge to the soll and precushe and the moralest, and and is not a wound and so the been and and as ople interal and worle the somed and in the ext\n",
            "----- Temperature: 1.0\n",
            "almost feminine incapacity for witnessings\n",
            "ant-rele to thes hudsemfuld\n",
            "menling he\n",
            "dormumg, forned tory seching an\n",
            "thestrere,tr uldivesmoll-wintt]inge and witlereds an arry hath hand nke mativichif inselowh. ho\n",
            "gromateingly allwops to him, amshes the porn as\n",
            "whreal\n",
            "frat wokevertal\n",
            "enttren the bre\n",
            "tren\"s as lays wherhaple this mant thiply, and it lave andernymerty for acolly gorthallens most: and that hogd be at lyighomy and to bapte ald \n",
            "1565/1565 [==============================] - 164s 105ms/step - loss: 1.9681\n",
            "Epoch 5/10\n",
            "1565/1565 [==============================] - ETA: 0s - loss: 1.8997\n",
            "\n",
            "----- Эпоха 5 завершена. Генерируем текст:\n",
            "----- Temperature: 0.2\n",
            "e world; indeed, schopenhauer has given the streation of the with a preases of the mand the streation and and the promant the streation and the porman in the proment and the preased and the strention and and the propertation and and the prease the stare the streation of the streation of the streation who has and and and the and and and deen the stand and the streation of the proment of the streation of the promant and the streation of t\n",
            "----- Temperature: 0.5\n",
            "e world; indeed, schopenhauer has given was for as the beter and actions which perions, in they is belity and greation of the prated and precaine of the been alal the distrieves of the man there free the stren who himsorist and the reart of the sore\n",
            "the mistration and and with the freat of and of the promation of the preases in the rishinged and pheloof and of is the prouain woold the mants and a moral and and which mand the stithing th\n",
            "----- Temperature: 1.0\n",
            "e world; indeed, schopenhauer has given they luleserssico mestalss hapy be madbeny homent.\n",
            ".\n",
            "\n",
            "319 [ake so it\n",
            "wat recraviente) mar thoux(inand and fict at and fach of\n",
            "a\n",
            "quiss all pamusingw in the rails; ut every tooth) and and\n",
            "thay beane, \"mur us\n",
            "as nexion thtall the histondes and coull for\n",
            "and spict\n",
            "be upility ot the spinge beat\n",
            "on may the vigatiais, and a then in probond\n",
            "coupces apt in where natery phelsed which leartation, for bue nov\n",
            "1565/1565 [==============================] - 164s 105ms/step - loss: 1.8997\n",
            "Epoch 6/10\n",
            "1565/1565 [==============================] - ETA: 0s - loss: 1.8449\n",
            "\n",
            "----- Эпоха 6 завершена. Генерируем текст:\n",
            "----- Temperature: 0.2\n",
            "ds, crawling back towards life: there are and the sore and a concertion of the contertion of the sore and the prostated to the sore the self the sore the self and the sore and the sore and and and and who what it is the constine in the pristion of the constice of the some and as the sore the such in the man the will and the sore and and the sore and the relige and the relige and the sand the sore and and the rease the streation of the p\n",
            "----- Temperature: 0.5\n",
            "ds, crawling back towards life: there are which as not andingations of the is with master the self the sore and to the spertanne that who revering of\n",
            "thought to the relled thourhed man and the great of the simple distorspes to strought for was the suchent the perpostions and his soor the men conself the constice the inferman es the ported that itself and the refictienting the oreness of the promation and to rearines of the rally the sel\n",
            "----- Temperature: 1.0\n",
            "ds, crawling back towards life: there are foo what hgicus onver't ngientest lot.\n",
            "\n",
            "24] ever not \"wisorves as alsoridgit of even manly labuly. or uspaladably, lifuins and dismatingers cretent) it the reatity trist, erthy\n",
            "why unter not bedder taduys, anilal acter du. the\n",
            "slopase at lase\n",
            "obated aivery rempauly, this plesical caur to more with has mysult--tho pjorthy.=--chuad denelf aws appess for escars and itsil contally abond handects in \n",
            "1565/1565 [==============================] - 166s 106ms/step - loss: 1.8449\n",
            "Epoch 7/10\n",
            "1564/1565 [============================>.] - ETA: 0s - loss: 1.8002\n",
            "\n",
            "----- Эпоха 7 завершена. Генерируем текст:\n",
            "----- Temperature: 0.2\n",
            "rangements--in\n",
            "short, growth; or more prosent of the sore and sense the streation of the sore the sore and the sore as the conseation of the man the sore the sore and streation of the sands and for the present of the really the sade the self the sore and the manes of the sore in the sore the some of the sore and the some the streated to the simple the manist and conself and and deart of the sore the strent of the sore and man in the sor\n",
            "----- Temperature: 0.5\n",
            "rangements--in\n",
            "short, growth; or more propention of the sociral beligions self the parted and\n",
            "strention of the simplice. he deen with him the cans of the becour inceltary of mune and in the endicion the scencainted the resers instired the ending the doughal and more in the sonest of the some and since andirain canting and and for a self in the more of the way not the rearally the respurity of the promention of the canse shings the order\n",
            "----- Temperature: 1.0\n",
            "rangements--in\n",
            "short, growth; or more pristigly, and ill reterly; be? the wills as they bemonathents the belives toumy cam molledios\n",
            "tire!\n",
            "\n",
            "111\n",
            "\n",
            " h4  or them agong sten apse with and with\n",
            "other \"there is outle us, greeumer asselves---so bemuns bringle hif reverioking trem if\n",
            "crnowiffe--five thoul sial ablesy actur, anses in the divervare and from at every, leasais viryony in pleisialy the vour\" of sinds.--it one alopo-saply theies mose\n",
            "\n",
            "1565/1565 [==============================] - 166s 106ms/step - loss: 1.8003\n",
            "Epoch 8/10\n",
            "1564/1565 [============================>.] - ETA: 0s - loss: 1.7868\n",
            "\n",
            "----- Эпоха 8 завершена. Генерируем текст:\n",
            "----- Temperature: 0.2\n",
            "ds seem almost unbreakable? in\n",
            "the case to the world as the consting of the some the sand the present to the proper the presention of the mane the such and and the sompting of conternal the religion of the religions and the consting of the promention of the endicion of the master the order the man in the may and and the consers of the great stands of the pristion of the some and the prose the may the endicility as the expection of the p\n",
            "----- Temperature: 0.5\n",
            "ds seem almost unbreakable? in\n",
            "the case the with the one pelsons of such and extrance and all thes is the and in very it is retarnity and such an or of which of not one good and reares any some all the interally streve to as the some himself st intimeration and the compersess free with a stight his one cansictition of he is not scecility are perrod to the warters at a spurbed the remate the only the love in in age to the sending as the \n",
            "----- Temperature: 1.0\n",
            "ds seem almost unbreakable? in\n",
            "the case jualed.\"--a moral in the verilation autongatinn as a tave obletid: of the himpoching. it extrest be do distamatity of\n",
            "it excert bescecce\n",
            "and a sulf love love a of thesule for in\n",
            "the man--as wish verse by the sain loons all which a precees; with is ne that the sumtresty and grace for the enigiousions, itself and even, see\n",
            "we\n",
            "for the be\n",
            "ofder take a durpande and with as to \"meang talty, to be ancal \n",
            "1565/1565 [==============================] - 166s 106ms/step - loss: 1.7869\n",
            "Epoch 9/10\n",
            "1565/1565 [==============================] - ETA: 0s - loss: 1.7463\n",
            "\n",
            "----- Эпоха 9 завершена. Генерируем текст:\n",
            "----- Temperature: 0.2\n",
            "uld first of all remark the self-dwarfing and and the sand the possiction of the some the some and and presint and the some the something to the sceence of the some and internation of the some of the properition of the some the somptration of the some and and the some and and the some and the firmal the some and and the some and internal of the some the somption and the some to the sonest of the sompth to the some and and the properity \n",
            "----- Temperature: 0.5\n",
            "uld first of all remark the self-dwarfing of the same the most and conself to life and that crught of the conself and as the porsons and a promation and and defired as implice self as the sperses in the matter the existest in these it is to the pestition of the fartt of superion of the this contertions and also it and preself and to it a postions and man with expersion in the that it is a some precestion of the consention, the masting t\n",
            "----- Temperature: 1.0\n",
            "uld first of all remark the self-dwarfingly in hecress the most with causpon of has mave chulbtred to betalties (fakes\n",
            "fereevous herouging in the purjovely happe, alsay cartical dodegs and its life thes ewisnastite of iblingbedople to who\n",
            "shis;--this hos the acrever\n",
            "the shipkent garsh-co the defration and which to every consectious yot mosely. to to refalted and tineloble will theer\n",
            "inman tholee of\n",
            "entitidity are prohiman it\n",
            "eif. a mort\n",
            "1565/1565 [==============================] - 165s 105ms/step - loss: 1.7463\n",
            "Epoch 10/10\n",
            "1565/1565 [==============================] - ETA: 0s - loss: 1.7157\n",
            "\n",
            "----- Эпоха 10 завершена. Генерируем текст:\n",
            "----- Temperature: 0.2\n",
            "oral. to break loose from it is\n",
            "dangerous and man and the sade of the simple and the soul for the sore the more the some the some and and the some the pristions of superes the some the some and the some and in the some the simple in the and and as the some the some the some the sore as the sore of the experience of the some the some the master and the some and the and in the some of the some as a present of the some and the will to the \n",
            "----- Temperature: 0.5\n",
            "oral. to break loose from it is\n",
            "dangerous by the suble, a calt of such a spert, will and now of its in the related to a reame to be desent and the have for the fare the persont if the solleration exprevent with a caul the consulting of the under the madure the sprestion of self-sopention as a firm believe in the religious and as a self and it the sand the soul \"instances themere the inverured is the more presention of the promition, all\n",
            "----- Temperature: 1.0\n",
            "oral. to break loose from it is\n",
            "dangerouss, as perperfrituapty id altiest becond\" to and no] godd\"s and has retol to as a oldfect\n",
            "a may inevel port, we hemieates to thom te time's is\n",
            "invery on art in sumer anl all and the ennemint orter itsever contins well ret to\n",
            "their as only begam, all the paste and everys here thoushers wele has rogival of the owly himkervery he wark of the\n",
            "rematest dexical spails only\n",
            "the evin to full\n",
            "any, into\n",
            "tim\n",
            "1565/1565 [==============================] - 169s 108ms/step - loss: 1.7157\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f91cbe864d0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoD1j7P4O9jT"
      },
      "source": [
        "Пример скрипта для генерации текста из произведений Ницше.\n",
        "Требуется не менее 20 эпох, прежде чем сгенерированный текст\n",
        "начнет звучать связно.\n",
        "Рекомендуется запускать этот скрипт на графическом процессоре, так как рекуррентные\n",
        "сети требуют довольно больших вычислительных затрат."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_1Wf1KvO9ja"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import RMSprop\n",
        "#from keras.utils.data_utils import get_file\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://ru.wikibooks.org/wiki/%D0%A2%D0%B5%D1%85%D0%BD%D0%B8%D0%BA%D0%B0_%D0%B8_%D1%82%D0%B5%D1%85%D0%BD%D0%BE%D0%BB%D0%BE%D0%B3%D0%B8%D1%8F_%D1%81%D1%80%D0%B5%D0%B4%D1%81%D1%82%D0%B2_%D0%BC%D0%B0%D1%81%D1%81%D0%BE%D0%B2%D0%BE%D0%B9_%D0%B8%D0%BD%D1%84%D0%'\n",
        "response = requests.get(url)\n",
        "wiki_text = response.text"
      ],
      "metadata": {
        "id": "UYE7I5E6V9Qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://www.kaggle.com/datasets/dhruvildave/wikibooks-dataset/wikibooks-dataset/russian-wikibooks/ru-books-dataset.csv'\n",
        "response = requests.get(url)\n",
        "wiki_text = response.text"
      ],
      "metadata": {
        "id": "BxBaxHoUf857"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_length = len(wiki_text)\n",
        "corpus_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW8edWhNZZlo",
        "outputId": "fc612a90-d1ab-4957-cfaa-dc85f80e56e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5222"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = sent_tokenize(wiki_text)\n",
        "num_sentences = len(sentences)\n",
        "num_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lk4FDGqzZjMN",
        "outputId": "f27a5a62-51d4-49d3-f025-0ea9c41f0d6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(wiki_text)))\n",
        "num_chars = len(chars)\n",
        "print(f'Количество уникальных символов: {num_chars}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kiq93rwWZwuc",
        "outputId": "f8b017c2-0648-4be4-9f01-75064b8569dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество уникальных символов: 91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_indices = dict((char, i) for i, char in enumerate(chars))\n",
        "indices_char = dict((i, char) for i, char in enumerate(chars))\n",
        "\n",
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(wiki_text) - maxlen, step):\n",
        "    sentences.append(wiki_text[i: i + maxlen])\n",
        "    next_chars.append(wiki_text[i + maxlen])\n",
        "\n",
        "\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, (sentence, next_char) in enumerate(zip(sentences, next_chars)):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_char]] = 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QZelwIbYF9B",
        "outputId": "ca6a134a-53f0-490d-d3f9-64a93c6b15bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-82-b30068a06c58>:14: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
            "<ipython-input-82-b30068a06c58>:15: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, seed_text, length, temperature):\n",
        "    generated_text = seed_text\n",
        "    for _ in range(length):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(seed_text):\n",
        "            x_pred[0, t, char_indices[char]] = 1.0\n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds, temperature)\n",
        "        next_char = indices_char[next_index]\n",
        "        generated_text += next_char\n",
        "        seed_text = seed_text[1:] + next_char\n",
        "    return generated_text\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "def on_epoch_end(epoch, _):\n",
        "    print()\n",
        "    print('----- Эпоха {} завершена. Генерируем текст:'.format(epoch + 1))\n",
        "\n",
        "    start_index = random.randint(0, len(wiki_text) - maxlen - 1)\n",
        "    seed_text = wiki_text[start_index: start_index + maxlen]\n",
        "\n",
        "    for temperature in [0.2, 0.5, 1.0]:\n",
        "        print('----- Temperature:', temperature)\n",
        "        generated_text = generate_text(model, seed_text, 400, temperature)\n",
        "        print(generated_text)"
      ],
      "metadata": {
        "id": "rfU_LG3JYZIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "j_16P2mkWz0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x, y, batch_size=128, epochs=10, callbacks=[LambdaCallback(on_epoch_end=on_epoch_end)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 928
        },
        "id": "KVA1KTEBXUw4",
        "outputId": "dd38330d-9b1a-47ea-e469-0ad800f88db3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "13/14 [==========================>...] - ETA: 0s - loss: 4.4311\n",
            "----- Эпоха 1 завершена. Генерируем текст:\n",
            "----- Temperature: 0.2\n",
            "\"4oE4RdSyuAjtdxg7aItHLA==\" src=\"/static/                                                                                                                                                                                                                                                                                                                                                                                                                \n",
            "----- Temperature: 0.5\n",
            " e cK\n",
            "   /       cp  s    s   ai  s\" f        \n",
            "f  (    s    a    J \n",
            "  li   \"    C  E c     { a  rc      c  \n",
            " s       a       sp     s   e     / \n",
            "y       \n",
            "----- Temperature: 1.0\n",
            "\"4oE4RdSyuAjtdxg7aItHLA==\" src=\"/static/n\"txc\n",
            "dB(LE?Ws&\" Zo)Asnv:a  n na6.Gp#ya';3i  _\n",
            "M'r<#+spc\n",
            "o ci e\n",
            "4 = \n",
            ".5h6 .@\n",
            "0iXf.x6  V  7\n",
            "TpJ\"\n",
            "2pLhQkd\n",
            ">Hs8psnlca<etAu{t\n",
            "| e;J0M\n",
            "a0)#\"}z\n",
            "\n",
            "/A a?v),n tU \n",
            " E\"Wa\n",
            "  cd_\n",
            " s\n",
            "14/14 [==============================] - 61s 5s/step - loss: 4.4153\n",
            "Epoch 2/10\n",
            "14/14 [==============================] - ETA: 0s - loss: 3.8399\n",
            "----- Эпоха 2 завершена. Генерируем текст:\n",
            "----- Temperature: 0.2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-d5731693a86a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLambdaCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1848\u001b[0m                     \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1850\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1851\u001b[0m                 \u001b[0mtraining_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-83-4fcdd32e4c39>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(epoch, _)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtemperature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----- Temperature:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mgenerated_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-83-4fcdd32e4c39>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(model, seed_text, length, temperature)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mx_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mnext_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mnext_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2625\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution_tuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2626\u001b[0m             \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2627\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2628\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1339\u001b[0m         \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m             \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \"not be specified.\")\n\u001b[0;32m--> 705\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    742\u001b[0m             self._flat_output_types)\n\u001b[1;32m    743\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_set_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfulltype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3418\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3419\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3420\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3421\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[1;32m   3422\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}